# 第一章 学习方法
## 1.1 监督学习
应用复杂问题时，大部分时候并不知道如何给定输入到输出的具体方法  
解决策略是让计算机从样本数据中学习输入到输出的具体方法  
使用样例来合成计算机程序的过程叫学习方法，其中样例是输入/输出对，称为监督学习  
输入/输出对通常反映了把输入映射到输出的一种函数关系  
批量学习：在学习的开始，把全部数据提供给学习器（模型）  
在线学习：一次只让学习器接受一个样例，并在接受正确输出前给出自己（学习器）对输出的估计  
## 1.2 学习和泛化性
泛化性：一个能把训练数据之外的新样本数据正确分类的能力称之为泛化能力（泛化性）  
一致假设：一个假设能够对所有训练数据正确分类，则称这个假设是一致的。  

## 1.3 提高泛化性
为了得到一致假设而使假设变的过度复杂称之为过拟合。  
控制此问题的方法是限制假设的规模：  
Ockham准则：如无必要，不必增加复杂性->更精细的复杂性必须能够显著提高训练数据的的分类正确率  
最小描述长度（MDL）：其函数描述长度与训练错误列表长度之和最短。  
有两种统计结果：1.一种是衡量了给定训练样例有限时可获得的泛化性能。2.另一种是渐进式统计结果，他研究了当样例数目趋近于无穷时的泛化性能  
似然性：即可能性，

## 1.5 用于学习的支持向量机
svm是在高维特征空间使用线性函数假设空间的学习系统
